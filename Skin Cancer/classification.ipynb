{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib as mpl\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "from skimage.io import imsave, imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_h = 224\n",
    "resize_w = 224\n",
    "np.random.seed(7)\n",
    "data_dir = '/home/harry/viii sem/AI'\n",
    "\n",
    "input_dir = data_dir + '/melanoma'\n",
    "other_dir = data_dir + '/others'\n",
    "\n",
    "train_dir = data_dir + '/gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    total=len(os.listdir(input_dir))+len(os.listdir(other_dir))\n",
    "    print('Total number of images = ',total)\n",
    "    imgs=[]\n",
    "    y=[]\n",
    "    i = 0\n",
    "\n",
    "    images = os.listdir(input_dir)\n",
    "    for image_name in images:\n",
    "        img = cv2.imread(os.path.join(input_dir, image_name))\n",
    "        img = cv2.resize(img, (resize_h, resize_w))\n",
    "        img = img_to_array(img)\n",
    "        imgs.append(img)\n",
    "        y.append(1)\n",
    "        #print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    len1 = i\n",
    "\n",
    "    images = os.listdir(other_dir)\n",
    "    for image_name in images:\n",
    "        img = cv2.imread(os.path.join(other_dir, image_name))\n",
    "        img = cv2.resize(img, (resize_h, resize_w))\n",
    "        img = img_to_array(img)\n",
    "        \n",
    "        imgs.append(img)\n",
    "        y.append(0)\n",
    "\n",
    "        #print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    len0 = i - len1\n",
    "    imgs = np.array(imgs, dtype=\"float\")/255.0\n",
    "    print('Loading done...')\n",
    "    return imgs, y, len0, len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images =  2000\n",
      "Loading done...\n"
     ]
    }
   ],
   "source": [
    "X, Y, len0, len1 = load_data()\n",
    "np.save( 'imgs_class.npy', X)\n",
    "np.save('imgs_label.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('imgs_class.npy')\n",
    "#Y = np.load('imgs_label.npy')\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.25, random_state=42, shuffle = True)\n",
    "del X\n",
    "del Y\n",
    "trainY = np_utils.to_categorical(trainY)\n",
    "test2Y = testY\n",
    "testY = np_utils.to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 6)       456       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 6)       906       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 6)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18816)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               2258040   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 170       \n",
      "=================================================================\n",
      "Total params: 2,269,736\n",
      "Trainable params: 2,269,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " Weight =  4.347593582887701\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "model = Sequential()\n",
    "def get_simple_cnn_model():\n",
    "\n",
    "    input_img = Input(shape=((resize_w,resize_h,3)))  \n",
    "\n",
    "    x = Conv2D(6, (5, 5), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same',strides = (2,2))(x)\n",
    "    x = Conv2D(6, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2,2), padding='same',strides = (2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(120, kernel_initializer='normal', activation='relu')(x)\n",
    "    x = Dense(84, kernel_initializer='normal', activation='relu')(x)\n",
    "    x = Dense(2, kernel_initializer='normal', activation='softmax')(x)\n",
    "\n",
    "    model = Model(input_img, x)   \n",
    "    model.compile(optimizer='Adadelta', loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "    print (model.summary())\n",
    "    return model\n",
    "\t\n",
    "model = get_simple_cnn_model()\n",
    "print(' Weight = ', len0/len1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 124s 82ms/step - loss: 1.1292 - acc: 0.6007 - val_loss: 0.6420 - val_acc: 0.8060\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 122s 81ms/step - loss: 1.1403 - acc: 0.6327 - val_loss: 0.5997 - val_acc: 0.8020\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 153s 102ms/step - loss: 1.1199 - acc: 0.5153 - val_loss: 0.6384 - val_acc: 0.6660\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 137s 91ms/step - loss: 1.0897 - acc: 0.5580 - val_loss: 0.5700 - val_acc: 0.8040\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 127s 85ms/step - loss: 1.0961 - acc: 0.5460 - val_loss: 0.7185 - val_acc: 0.3280\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 137s 92ms/step - loss: 1.0760 - acc: 0.5427 - val_loss: 0.4948 - val_acc: 0.8080\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 122s 81ms/step - loss: 1.0560 - acc: 0.6013 - val_loss: 0.5942 - val_acc: 0.6720\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 117s 78ms/step - loss: 1.0573 - acc: 0.5940 - val_loss: 0.6412 - val_acc: 0.5760\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 99s 66ms/step - loss: 1.0275 - acc: 0.6167 - val_loss: 0.5940 - val_acc: 0.6400\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 99s 66ms/step - loss: 0.9741 - acc: 0.6720 - val_loss: 0.5596 - val_acc: 0.6960\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 97s 65ms/step - loss: 0.9627 - acc: 0.6500 - val_loss: 0.5856 - val_acc: 0.6700\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 98s 66ms/step - loss: 0.8874 - acc: 0.7213 - val_loss: 0.5889 - val_acc: 0.6740\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 102s 68ms/step - loss: 0.8082 - acc: 0.7467 - val_loss: 0.5304 - val_acc: 0.7400\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 99s 66ms/step - loss: 0.7121 - acc: 0.7940 - val_loss: 0.8753 - val_acc: 0.5380\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 98s 65ms/step - loss: 0.6107 - acc: 0.8353 - val_loss: 0.6584 - val_acc: 0.6280\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 97s 65ms/step - loss: 0.4811 - acc: 0.8847 - val_loss: 0.5944 - val_acc: 0.7700\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 98s 65ms/step - loss: 0.3600 - acc: 0.9160 - val_loss: 0.6600 - val_acc: 0.7580\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 100s 67ms/step - loss: 0.2757 - acc: 0.9393 - val_loss: 0.7695 - val_acc: 0.7380\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 106s 70ms/step - loss: 0.1488 - acc: 0.9647 - val_loss: 1.0521 - val_acc: 0.8080\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 101s 67ms/step - loss: 0.1224 - acc: 0.9787 - val_loss: 0.9384 - val_acc: 0.7300\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 103s 69ms/step - loss: 0.0540 - acc: 0.9913 - val_loss: 1.0285 - val_acc: 0.7960\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 106s 70ms/step - loss: 0.0241 - acc: 0.9960 - val_loss: 1.1424 - val_acc: 0.7900\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 110s 74ms/step - loss: 0.0650 - acc: 0.9933 - val_loss: 1.0592 - val_acc: 0.7780\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 106s 71ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2474 - val_acc: 0.7880\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 106s 71ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.4501 - val_acc: 0.7940\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 109s 72ms/step - loss: 0.0466 - acc: 0.9927 - val_loss: 1.2695 - val_acc: 0.7980\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 110s 73ms/step - loss: 0.0073 - acc: 0.9993 - val_loss: 1.6765 - val_acc: 0.6620\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 107s 72ms/step - loss: 0.0040 - acc: 0.9993 - val_loss: 1.4262 - val_acc: 0.7800\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 107s 72ms/step - loss: 3.8765e-04 - acc: 1.0000 - val_loss: 1.5157 - val_acc: 0.7780\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 112s 75ms/step - loss: 2.7569e-04 - acc: 1.0000 - val_loss: 1.6763 - val_acc: 0.7860\n"
     ]
    }
   ],
   "source": [
    "classifier = model.fit(trainX,trainY, batch_size = 20, epochs = 30, verbose = True, validation_data = (testX, testY),class_weight = {0:1, 1:len0/len1})\n",
    "PredY = model.predict(testX,verbose=\"True\")\n",
    "y_pred = []\n",
    "for item in PredY:\n",
    "\tif item[0] > 0.5:\n",
    "\t\ty_pred.append(0)\n",
    "\telse:\n",
    "\t\ty_pred.append(1)\n",
    "\n",
    "y_pred = np.array(y_pred,dtype = \"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = [0.87367178]\n"
     ]
    }
   ],
   "source": [
    "print('F1 =', f1_score(test2Y, y_pred, average=None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix =  [[23, 73], [34, 370]]\n",
      "precision_score:  0.40350877192982454\n",
      "recall_score:  0.23958333333333334\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test2Y, y_pred).ravel()\n",
    "matrix = [[tp, fn], [fp, tn]]\n",
    "print('Confusion matrix = ', matrix)\n",
    "print('precision_score: ', precision_score(test2Y, y_pred, pos_label=1, average='binary'))\n",
    "print('recall_score: ', recall_score(test2Y, y_pred, pos_label=1, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
